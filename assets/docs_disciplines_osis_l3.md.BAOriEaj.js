import{_ as a,c as i,o as n,ag as p}from"./chunks/framework.D4Vqf8I7.js";const o=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"docs/disciplines/osis/l3.md","filePath":"docs/disciplines/osis/l3.md","lastUpdated":1755788837000}'),l={name:"docs/disciplines/osis/l3.md"};function t(e,s,h,k,r,d){return n(),i("div",null,s[0]||(s[0]=[p(`<p><strong>Interleaving, Race Condition и Взаимоисключения</strong></p><p>Под активностями мы будем понимать последовательное выполнение ряда действий, направленных на достижение определенной цели. Мы будем разбивать активности на некоторые неделимые, или атомарные (операция выполняется либо целиком, либо вообще не выполняется), операции. Например, активность «приготовление бутерброда» можно разбить на следующие атомарные операции:</p><ol><li>Отрезать ломтик хлеба.</li><li>Отрезать ломтик колбасы.</li><li>Намазать ломтик хлеба маслом.</li><li>Положить ломтик колбасы на подготовленный ломтик хлеба.</li></ol><p>Неделимые операции могут иметь внутренние невидимые действия (взять батон хлеба в левую руку, взять нож в правую руку, произвести отрезание). Мы же называем их неделимыми потому, что считаем выполняемыми за раз, без прерывания деятельности.</p><p>Пусть имеется две активности:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>P: a b c</span></span>
<span class="line"><span>Q: d e f</span></span></code></pre></div><p>где a, b, c, d, e, f — атомарные операции. При последовательном выполнении активностей мы получаем такую последовательность атомарных действий:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>PQ: a b c d e f</span></span></code></pre></div><p>При исполнении этих активностей псевдопараллельно активности могут расслоиться на неделимые операции с различным чередованием, то есть может произойти то, что на английском языке принято называть словом interleaving. Представьте все возможные варианты чередования a, b, c, d, e, f.</p><p>Атомарные операции активностей могут чередоваться всевозможными различными способами с сохранением порядка расположения внутри активностей. Так как псевдопараллельное выполнение двух активностей приводит к чередованию их неделимых операций, результат псевдопараллельного выполнения может отличаться от результата последовательного выполнения. Рассмотрим пример. Пусть у нас имеется две активности P и Q, состоящие из двух атомарных операций каждая:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>P: x=2      Q: x=3</span></span>
<span class="line"><span>  y=x-1      y=x+1</span></span></code></pre></div><p>Что мы получим в результате их псевдопараллельного выполнения, если переменные x и y являются для активностей общими? Очевидно, что возможны четыре разных набора значений для пары (x, y): (3, 4), (2, 1), (2, 3) и (3, 2). Мы будем говорить, что набор активностей (например, программ) <strong>детерминирован (определен)</strong>, если всякий раз при псевдопараллельном исполнении для одного и того же набора входных данных он дает одинаковые выходные данные. Выше приведен пример недетерминированного набора программ.</p><p>Можно ли до получения результатов определить, является ли набор активностей детерминированным или нет? Для этого существуют достаточные условия Бернстайна.</p><p>Введем наборы входных и выходных переменных программы. Для каждой атомарной операции наборы входных и выходных переменных — это наборы переменных, которые атомарная операция считывает и записывает. Набор входных переменных программы R(P) (R от слова read) суть объединение наборов входных переменных для всех ее неделимых действий. Аналогично, набор выходных переменных программы W(P) (W от слова write) суть объединение наборов выходных переменных для всех ее неделимых действий. Например, для программы:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>P: x=u+v</span></span>
<span class="line"><span>  y=x*w</span></span></code></pre></div><p>получаем R(P) = {u, v, x, w}, W(P) = {x, y}. Заметим, что переменная x присутствует как в R(P), так и в W(P).</p><p>Теперь сформулируем условия Бернстайна.</p><p>Если для двух данных активностей P и Q:</p><ul><li>пересечение W(P) и W(Q) пусто,</li><li>пересечение W(P) с R(Q) пусто,</li><li>пересечение R(P) и W(Q) пусто,</li></ul><p>тогда выполнение P и Q детерминировано.</p><p>Если эти условия не соблюдены, возможно, параллельное выполнение P и Q детерминировано, а может быть, и нет.</p><p>Случай двух активностей естественным образом обобщается на их большее количество.</p><p>Условия Бернстайна информативны, но слишком жестки. По сути дела, они требуют практически невзаимодействующих процессов. А нам хотелось бы, чтобы детерминированный набор образовывали активности, совместно использующие информацию и обменивающиеся ею. Для этого нам необходимо ограничить число возможных чередований атомарных операций, исключив некоторые чередования с помощью механизмов синхронизации выполнения программ, обеспечив тем самым упорядоченный доступ программ к некоторым данным.</p><p>Про недетерминированный набор программ (и активностей вообще) говорят, что он имеет <strong>race condition</strong> (состояние гонки, состояние состязания). В приведенном выше примере процессы состязаются за вычисление значений переменных x и y.</p><p>Задачу упорядоченного доступа к разделяемым данным (устранение race condition) в том случае, когда нам не важна его очередность, можно решить, если обеспечить каждому процессу эксклюзивное право доступа к этим данным. Каждый процесс, обращающийся к разделяемым ресурсам, исключает для всех других процессов возможность одновременного общения с этими ресурсами, если это может привести к недетерминированному поведению набора процессов. Такой прием называется <strong>взаимоисключением (mutual exclusion)</strong>. Если очередность доступа к разделяемым ресурсам важна для получения правильных результатов, то одними взаимоисключениями уже не обойтись, нужна взаимосинхронизация поведения программ.</p><p><strong>Критическая секция</strong></p><p>Критическая секция — это часть программы, исполнение которой может привести к возникновению race condition для определенного набора программ. Чтобы исключить эффект гонок по отношению к некоторому ресурсу, необходимо организовать работу так, чтобы в каждый момент времени только один процесс мог находиться в своей критической секции, связанной с этим ресурсом.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>+-----------------------------------+</span></span>
<span class="line"><span>|          Критическая секция       |</span></span>
<span class="line"><span>|  +-----------------------------+  |</span></span>
<span class="line"><span>|  | Процесс A: Захват ресурса   |  |</span></span>
<span class="line"><span>|  | ... Операции с ресурсом ... |  |</span></span>
<span class="line"><span>|  | Освобождение ресурса        |  |</span></span>
<span class="line"><span>|  +-----------------------------+  |</span></span>
<span class="line"><span>|                                   |</span></span>
<span class="line"><span>|  +-----------------------------+  |</span></span>
<span class="line"><span>|  | Процесс B: Ожидание доступа |  |</span></span>
<span class="line"><span>|  | ...                         |  |</span></span>
<span class="line"><span>|  +-----------------------------+  |</span></span>
<span class="line"><span>+-----------------------------------+</span></span></code></pre></div><p>Сделать процесс добывания хлеба атомарной операцией можно было бы следующим образом: перед началом этого процесса закрыть дверь изнутри на засов и уходить добывать хлеб через окно, а по окончании процесса вернуться в комнату через окно и отодвинуть засов. Тогда пока один студент добывает хлеб, все остальные находятся в состоянии ожидания под дверью.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>+-------------------------------+</span></span>
<span class="line"><span>| Комната: [Дверь] [Окно]       |</span></span>
<span class="line"><span>|                               |</span></span>
<span class="line"><span>| Студент A:                    |</span></span>
<span class="line"><span>|   - Закрыл засов              |</span></span>
<span class="line"><span>|   - Вышел через окно          |</span></span>
<span class="line"><span>|   - Добывает хлеб             |</span></span>
<span class="line"><span>|   - Вернулся через окно       |</span></span>
<span class="line"><span>|   - Открыл засов              |</span></span>
<span class="line"><span>|                               |</span></span>
<span class="line"><span>| Студент B:                    |</span></span>
<span class="line"><span>|   - Ждет у двери              |</span></span>
<span class="line"><span>|   ...                         |</span></span>
<span class="line"><span>+-------------------------------+</span></span></code></pre></div><p>Итак, для решения задачи необходимо, чтобы в том случае, когда процесс находится в своем критическом участке, другие процессы не могли войти в свои критические участки.</p><p><strong>Программные алгоритмы организации взаимодействия процессов</strong></p><p>Пять условий, которые должны выполняться для хорошего программного алгоритма организации взаимодействия процессов, имеющих критические участки, если они могут проходить их в произвольном порядке:</p><ol><li>Задача должна быть решена чисто программным способом на обычной машине, не имеющей специальных команд взаимоисключения.</li><li>Не должно существовать никаких предположений об относительных скоростях выполняющихся процессов или числе процессоров, на которых они исполняются.</li><li>Если процесс исполняется в своем критическом участке, то не существует никаких других процессов, которые исполняются в соответствующих критических секциях.</li><li>Процессы, которые находятся вне своих критических участков и не собираются входить в них, не могут препятствовать другим процессам входить в их собственные критические участки.</li><li>Не должно возникать неограниченно долгого ожидания для входа одного из процессов в свой критический участок.</li></ol><p><strong>Запрет прерываний</strong></p><div class="language-c vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (some condition) {</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    запретить все прерывания</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    critical_section</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    разрешить все прерывания</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    remainder_section</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>При условии, когда процесс входит в критическую секцию, запрет прерываний действует так: запрещает прерывания, входит в критическую секцию, разрешает прерывания, оставшиеся этапы.</p><p>Однако такое решение может иметь далеко идущие последствия, поскольку позволяет процессу пользователя разрешать и запрещать прерывания во всей вычислительной системе. Допустим, что пользователь случайно или по злому умыслу запретил прерывания в системе и зациклил или завершил свой процесс. Без перезагрузки системы в такой ситуации не обойтись.</p><p><strong>Переменная-замок</strong></p><div class="language-c vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">shared </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> lock </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> /* shared означает, что переменная является разделяемой */</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (some condition) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(lock);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    lock </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    critical_section</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    lock </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    remainder_section</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>Переменная-замок работает так: Процесс может войти в критическую секцию только тогда, когда значение этой переменной-замка равно 0, одновременно изменяя ее значение на 1 — закрывая замок; Выходит из критической секции, меняет значение переменной на 0; остальные этапы.</p><p>К сожалению, при внимательном рассмотрении мы видим, что такое решение не удовлетворяет условию взаимоисключения, так как действие <code>while(lock); lock = 1;</code> не является атомарным.</p><p><strong>Строгое чередование</strong></p><div class="language-c vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">shared </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> turn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (some condition) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(turn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">!=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i);</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    critical_section</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    turn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    remainder_section</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>Строгое чередование работает так: если переменная равна 1, то процесс готов войти в критический участок; Входит в критический участок; переменная меняется на 0 — процесс не может войти в критический участок; остальные этапы.</p><p>Процессы входят в критическую секцию строго по очереди: P0, P1, P0, P1, P0, ...</p><p>Если turn равно 1, и процесс P0 готов войти в критический участок, он не может сделать этого, даже если процесс P1 находится в remainder section.</p><p><strong>Флаги готовности</strong></p><div class="language-c vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">shared </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> ready</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">};</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (some condition) {</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    ready</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">ready</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i]);</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    critical_section</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    ready</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    remainder_section</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>Работает так: Для каждого процесса в массиве указано 0 — его состояние, поэтому знают о состоянии друг друга; Если переменная равна 1 — входит в критическую секцию; После выхода переменная меняется на 0; остальные этапы.</p><p>Полученный алгоритм обеспечивает взаимоисключение, позволяет процессу, готовому к входу в критический участок, войти в него сразу после завершения эпилога в другом процессе, но все равно нарушает условие прогресса.</p><p>После выполнения присваивания <code>ready[0]=1</code> планировщик передал процессор от процесса 0 процессу 1, который также выполнил присваивание <code>ready[1]=1</code>. После этого оба процесса бесконечно долго ждут друг друга на входе в критическую секцию. Возникает ситуация, которую принято называть <strong>тупиковой (deadlock)</strong>.</p><p><strong>Алгоритм Петерсона</strong></p><p>Первое решение проблемы, удовлетворяющее всем требованиям и использующее идеи ранее рассмотренных алгоритмов, было предложено датским математиком Деккером (Dekker). В 1981 году Петерсон (Peterson) предложил более изящное решение. Пусть оба процесса имеют доступ к массиву флагов готовности и к переменной очередности.</p><div class="language-c vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">shared </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> ready</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">};</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">shared </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> turn;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (some condition) {</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    ready</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    turn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">ready</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&amp;&amp;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> turn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i);</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    critical_section</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    ready</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    remainder_section</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>При исполнении пролога критической секции процесс Pi заявляет о своей готовности выполнить критический участок и одновременно предлагает другому процессу приступить к его выполнению. Если оба процесса подошли к прологу практически одновременно, то они оба объявят о своей готовности и предложат выполняться друг другу. При этом одно из предложений всегда следует после другого. Тем самым работу в критическом участке продолжит процесс, которому было сделано последнее предложение.</p><p>Давайте докажем, что все пять наших требований к алгоритму действительно удовлетворяются.</p><p>Удовлетворение требований 1 и 2 очевидно.</p><p>Докажем выполнение условия взаимоисключения методом от противного. Пусть оба процесса одновременно оказались внутри своих критических секций. Заметим, что процесс Pi может войти в критическую секцию, только если <code>ready[1-i] == 0</code> или <code>turn == i</code>. Заметим также, что если оба процесса выполняют свои критические секции одновременно, то значения флагов готовности для обоих процессов совпадают и равны 1. Могли ли оба процесса войти в критические секции из состояния, когда они оба одновременно находились в процессе выполнения цикла while? Нет, так как в этом случае переменная turn должна была бы одновременно иметь значения 0 и 1 (когда оба процесса выполняют цикл, значения переменных измениться не могут). Пусть процесс P0 первым вошел в критический участок, тогда процесс P1 должен был выполнить перед вхождением в цикл while по крайней мере один предваряющий оператор (<code>turn = 0;</code>). Однако после этого он не может выйти из цикла до окончания критического участка процесса P0, так как при входе в цикл <code>ready[0] == 1</code> и <code>turn == 0</code>, и эти значения не могут измениться до тех пор, пока процесс P0 не покинет свой критический участок. Мы пришли к противоречию. Следовательно, имеет место взаимоисключение.</p><p>Докажем выполнение условия прогресса. Возьмем, без ограничения общности, процесс P0. Заметим, что он не может войти в свою критическую секцию только при совместном выполнении условий <code>ready[1] == 1</code> и <code>turn == 1</code>. Если процесс P1 не готов к выполнению критического участка, то <code>ready[1] == 0</code>, и процесс P0 может осуществить вход. Если процесс P1 готов к выполнению критического участка, то <code>ready[1] == 1</code> и переменная turn имеет значение 0 либо 1, позволяя процессу P0 либо процессу P1 начать выполнение критической секции. Если процесс P1 завершил выполнение критического участка, то он сбросит свой флаг готовности <code>ready[1] == 0</code>, разрешая процессу P0 приступить к выполнению критической работы. Таким образом, условие прогресса выполняется.</p><p>Отсюда же вытекает выполнение условия ограниченного ожидания. Так как в процессе ожидания разрешения на вход процесс P0 не изменяет значения переменных, он сможет начать исполнение своего критического участка после не более чем одного прохода по критической секции процесса P1.</p><p><strong>Планирование процессов</strong></p><p><strong>Уровни планирования</strong></p><p>В первой лекции, рассматривая эволюцию компьютерных систем, мы говорили о двух видах планирования в вычислительных системах: планировании заданий и планировании использования процессора.</p><p>Планирование заданий используется в качестве <strong>долгосрочного планирования</strong> процессов. Оно отвечает за порождение новых процессов в системе, определяя ее степень <strong>мультипрограммирования, т. е. количество процессов, одновременно находящихся в ней</strong>. Если среднее количество процессов в компьютере не меняется, то новые процессы могут появляться только после завершения ранее загруженных. Поэтому долгосрочное планирование осуществляется достаточно редко. Решение о выборе для запуска того или иного процесса оказывает влияние на функционирование вычислительной системы на протяжении достаточно длительного времени. Отсюда и название этого уровня планирования — долгосрочное. В некоторых операционных системах долгосрочное планирование сведено к минимуму или отсутствует вовсе.</p><p>Планирование использования процессора применяется в качестве <strong>краткосрочного планирования</strong> процессов. Оно проводится, к примеру, при обращении исполняющегося процесса к устройствам ввода-вывода или просто по завершении определенного интервала времени. Поэтому краткосрочное планирование осуществляется, как правило, не реже одного раза в 100 миллисекунд. Выбор нового процесса для исполнения оказывает влияние на функционирование системы до наступления очередного аналогичного события, т. е. в течение короткого промежутки времени, чем и обусловлено название этого уровня планирования — краткосрочное.</p><p><strong>Swapping («перекачка»)</strong> — временное удаление какого-либо частично выполнившегося процесса из оперативной памяти на диск, а позже возвращение его обратно для дальнейшего выполнения. Это делается для повышения производительности.</p><p>Когда и какой из процессов нужно перекачать на диск и вернуть обратно, решается дополнительным промежуточным уровнем планирования процессов — <strong>среднесрочным.</strong></p><p><strong>Критерии планирования и требования к алгоритмам</strong></p><p>Цели:</p><ul><li>Справедливость — гарантировать каждому заданию или процессу определенную часть времени использования процессора, стараясь не допустить возникновения ситуации, когда процесс одного пользователя постоянно занимает процессор, в то время как процесс другого пользователя фактически не начинал выполняться.</li><li>Эффективность — постараться занять процессор на все 100% рабочего времени, не позволяя ему простаивать в ожидании процессов, готовых к исполнению. В реальных вычислительных системах загрузка процессора колеблется от 40 до 90%.</li><li>Сокращение полного времени выполнения (turnaround time) — обеспечить минимальное время между стартом процесса или постановкой задания в очередь для загрузки и его завершением.</li><li>Сокращение времени ожидания (waiting time) — сократить время, которое проводят процессы в состоянии готовность и задания в очереди для загрузки.</li><li>Сокращение времени отклика (response time) — минимизировать время, которое требуется процессу в интерактивных системах для ответа на запрос пользователя.</li></ul><p>Независимо от поставленных целей планирования желательно также, чтобы алгоритмы обладали следующими свойствами.</p><ul><li><strong>Были предсказуемыми</strong>. Одно и то же задание должно выполняться приблизительно за одно и то же время.</li><li><strong>Были связаны с минимальными накладными расходами.</strong> Если на каждые 100 миллисекунд, выделенные процессу для использования процессора, будет приходиться 200 миллисекунд на определение того, какой именно процесс получит процессор в свое распоряжение, и на переключение контекста, то такой алгоритм, очевидно, применять не стоит.</li><li><strong>Равномерно загружали ресурсы вычислительной системы</strong>, отдавая предпочтение тем процессам, которые будут занимать малоиспользуемые ресурсы.</li><li><strong>Обладали масштабируемостью</strong>, т. е. не сразу теряли работоспособность при увеличении нагрузки. Например, рост количества процессов в системе в два раза не должен приводить к увеличению полного времени выполнения процессов на порядок.</li></ul><p>Многие из приведенных выше целей и свойств являются противоречивыми. Улучшая работу алгоритма с точки зрения одного критерия, мы ухудшаем ее с точки зрения другого. Приспосабливая алгоритм под один класс задач, мы тем самым дискриминируем задачи другого класса.</p><p><strong>Параметры планирования</strong></p><p>Все параметры планирования можно разбить на две большие группы: статические параметры и динамические параметры. <strong>Статические параметры</strong> не изменяются в ходе функционирования вычислительной системы, <strong>динамические</strong> — подвержены постоянным изменениям.</p><p>К статическим параметрам вычислительной системы можно отнести <strong>предельные значения ее ресурсов</strong> (размер оперативной памяти, максимальное количество памяти на диске для осуществления свопинга, количество подключенных устройств ввода-вывода и т. п.). Динамические параметры системы описывают количество свободных ресурсов на данный момент.</p><p>К статическим параметрам процессов относятся характеристики, как правило присущие заданиям уже на этапе загрузки.</p><ul><li>Каким пользователем запущен процесс или сформировано задание.</li><li>Насколько важной является поставленная задача, т. е. каков приоритет ее выполнения.</li><li>Сколько процессорного времени запрошено пользователем для решения задачи.</li><li>Каково соотношение процессорного времени и времени, необходимого для осуществления операций ввода-вывода.</li><li>Какие ресурсы вычислительной системы (оперативная память, устройства ввода-вывода, специальные библиотеки и системные программы и т. д.) и в каком количестве необходимы заданию.</li></ul><p>Алгоритмы <strong>долгосрочного планирования</strong> используют статические и динамические параметры вычислительной системы и статические параметры.</p><p>Алгоритмы <strong>краткосрочного и среднесрочного планирования</strong> дополнительно учитывают и динамические характеристики процессов. Для среднесрочного планирования в качестве таких характеристик может использоваться следующая информация:</p><ul><li>сколько времени прошло с момента выгрузки процесса на диск или его загрузки в оперативную память;</li><li>сколько оперативной памяти занимает процесс;</li><li>сколько процессорного времени уже предоставлено процессу.</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>+-----------------------------------+</span></span>
<span class="line"><span>| Процесс:                          |</span></span>
<span class="line"><span>|  +----------+    +----------+     |</span></span>
<span class="line"><span>|  | CPU      |    | I/O      |     |</span></span>
<span class="line"><span>|  | burst    |    | burst    |     |</span></span>
<span class="line"><span>|  +----------+    +----------+     |</span></span>
<span class="line"><span>|                                   |</span></span>
<span class="line"><span>|  +----------+    +----------+     |</span></span>
<span class="line"><span>|  | CPU      |    | I/O      |     |</span></span>
<span class="line"><span>|  | burst    |    | burst    |     |</span></span>
<span class="line"><span>|  +----------+    +----------+     |</span></span>
<span class="line"><span>|                ...                |</span></span>
<span class="line"><span>+-----------------------------------+</span></span></code></pre></div><p><em>Рис. 3.1. Фрагмент деятельности процесса с выделением промежутков непрерывного использования процессора и ожидания ввода-вывода</em></p><p><strong>Для краткосрочного планирования:</strong></p><p>Деятельность любого процесса можно представить как последовательность циклов использования процессора и ожидания завершения операций ввода-вывода. Промежуток времени <strong>непрерывного использования процессора</strong> носит название <strong>CPU burst</strong>, а промежуток времени <strong>непрерывного ожидания ввода-вывода — I/O burst</strong>. Значения продолжительности последних и очередных CPU burst и I/O burst являются важными динамическими параметрами процесса.</p><p><strong>Вытесняющее и невытесняющее планирование</strong></p><p>Процесс планирования осуществляется частью операционной системы, называемой <strong>планировщиком</strong>.</p><p>Планировщик может принимать решения о выборе для исполнения нового процессора из числа находящихся в состоянии готовность в следующих четырех случаях:</p><ol><li>Когда процесс переводится из состояния исполнение в состояние закончил исполнение.</li><li>Когда процесс переводится из состояния исполнение в состояние ожидание.</li><li>Когда процесс переводится из состояния исполнение в состояние готовность (например, после прерывания от таймера).</li><li>Когда процесс переводится из состояния ожидание в состояние готовность (завершилась операция ввода-вывода или произошло другое событие).</li></ol><p>В случаях 1 и 2 процесс, находившийся в состоянии исполнение, не может дальше исполняться, и операционная система вынуждена осуществлять планирование, выбирая новый процесс для выполнения. В случаях 3 и 4 планирование может как проводиться, так и не проводиться, планировщик не вынужден обязательно принимать решение о выборе процесса для выполнения, процесс, находившийся в состоянии исполнение, может просто продолжить свою работу.</p><p><strong>Невытесняющее планирование</strong> — планирование осуществляется только в вынужденных ситуациях. Процесс занимает столько процессорного времени, сколько ему необходимо. При этом переключение процессов возникает только при желании самого исполняющегося процесса передать управление (для ожидания завершения операции ввода-вывода или по окончании работы). Однако возникает проблема возможности полного захвата процессора одним процессом, который вследствие каких-либо причин (например, из-за ошибки в программе) зацикливается и не может передать управление другому процессу. В такой ситуации спасает только перезагрузка всей вычислительной системы.</p><p>Если планировщик принимает и вынужденные, и невынужденные решения, говорят о <strong>вытесняющем (preemptive)</strong> планировании. Термин «вытесняющее планирование» возник потому, что исполняющийся процесс помимо своей воли может быть вытеснен из состояния исполнение другим процессом. <strong>Вытесняющее планирование</strong> обычно используется в системах разделения времени. В этом режиме планирования процесс может быть приостановлен в любой момент исполнения. Операционная система устанавливает специальный таймер для генерации сигнала прерывания по истечении некоторого интервала времени — кванта. После прерывания процессор передается в распоряжение следующего процесса. Временные прерывания помогают гарантировать приемлемое время отклика процессов для пользователей, работающих в диалоговом режиме, и предотвращают «зависание» компьютерной системы из-за зацикливания какой-либо программы.</p><p><strong>Алгоритмы планирования</strong></p><p><strong>First-Come, First-Served (FCFS)</strong></p><p>(первым пришел, первым обслужен)</p><p>Представим себе, что процессы, находящиеся в состоянии готовность, выстроены в очередь.</p><p>Когда процесс переходит в состояние готовность, он, а точнее, ссылка на его PCB помещается в конец этой очереди. Выбор нового процесса для исполнения осуществляется из начала очереди с удалением оттуда ссылки на его PCB. Очередь подобного типа имеет в программировании специальное наименование — FIFO (First In, First Out — первым вошел, первым вышел).</p><p>Такой алгоритм выбора процесса осуществляет невытесняющее планирование. Процесс, получивший в свое распоряжение процессор, занимает его до истечения текущего CPU burst. После этого для выполнения выбирается новый процесс из начала очереди.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Процесс    | Продолжительность очередного CPU burst</span></span>
<span class="line"><span>-----------|---------------------------------------</span></span>
<span class="line"><span>p0         | 13</span></span>
<span class="line"><span>p1         | 4</span></span>
<span class="line"><span>p2         | 1</span></span></code></pre></div><p>Преимуществом алгоритма FCFS является легкость его реализации, но в то же время он имеет и много недостатков. Рассмотрим следующий пример. Пусть в состоянии готовность находятся три процесса p0, p1 и p2, для которых известны времена их очередных CPU burst. Эти времена приведены в таблице выше в некоторых условных единицах. Для простоты будем полагать, что вся деятельность процессов ограничивается использованием только одного промежутка CPU burst, что процессы не совершают операций ввода-вывода и что время переключения контекста так мало, что им можно пренебречь. Если процессы расположены в очереди процессов, готовых к исполнению, в порядке p0, p1, p2, то картина их выполнения выглядит так, как показано на рисунке ниже.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Время:     0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18</span></span>
<span class="line"><span>p0:       [И][И][И][И][И][И][И][И][И][И][И][И][И]</span></span>
<span class="line"><span>p1:                                       [И][И][И][И]</span></span>
<span class="line"><span>p2:                                                   [И]</span></span></code></pre></div><p><em>Рис. 3.2. Выполнение процессов при порядке p0, p1, p2</em></p><p>Первым для выполнения выбирается процесс p0, который получает процессор на все время своего CPU burst, т. е. на 13 единиц времени. После его окончания в состояние исполнение переводится процесс p1, он занимает процессор на 4 единицы времени. И, наконец, возможность работать получает процесс p2. Время ожидания для процесса p0 составляет 0 единиц времени, для процесса p1 — 13 единиц, для процесса p2 — 13 + 4 = 17 единиц. Таким образом, среднее время ожидания в этом случае — (0 + 13 + 17)/3 = 10 единиц времени. Полное время выполнения для процесса p0 составляет 13 единиц времени, для процесса p1 — 13 + 4 = 17 единиц, для процесса p2 — 13 + 4 + 1 = 18 единиц. Среднее полное время выполнения оказывается равным (13 + 17 + 18)/3 = 16 единицам времени.</p><p>Если те же самые процессы расположены в порядке p2, p1, p0, то картина их выполнения будет соответствовать рисунку ниже.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Время:     0   1   2   3   4   5</span></span>
<span class="line"><span>p2:       [И]</span></span>
<span class="line"><span>p1:          [И][И][И][И]</span></span>
<span class="line"><span>p0:                   [И][И][И][И][И][И][И][И][И][И][И][И][И]</span></span></code></pre></div><p><em>Рис. 3.3. Выполнение процессов при порядке p2, p1, p0</em></p><p>Время ожидания для процесса p0 равняется 5 единицам времени, для процесса p1 — 1 единице, для процесса p2 — 0 единиц. Среднее время ожидания составит (5 + 1 + 0)/3 = 2 единицы времени. Это в 5 (!) раз меньше, чем в предыдущем случае. Полное время выполнения для процесса p0 получается равным 18 единицам времени, для процесса p1 — 5 единицам, для процесса p2 — 1 единице. Среднее полное время выполнения составляет (18 + 5 + 1)/3 = 8 единиц времени, что почти в 2 раза меньше, чем при первой расстановке процессов.</p><p>Как мы видим, среднее время ожидания и среднее полное время выполнения для этого алгоритма существенно зависят от порядка расположения процессов в очереди. Если у нас есть процесс с длительным CPU burst, то короткие процессы, перешедшие в состояние готовность после длительного процесса, будут очень долго ждать начала выполнения. <strong>Поэтому алгоритм FCFS практически неприменим для систем разделения времени — слишком большим получается среднее время отклика в интерактивных процессах.</strong></p><p><strong>Round Robin (RR)</strong></p><p>Модификацией алгоритма FCFS является алгоритм, получивший название Round Robin или сокращенно RR. По сути дела, это тот же самый алгоритм, только реализованный в режиме вытесняющего планирования. Каждый процесс находится около процессора небольшой фиксированный квант времени, обычно 10 — 100 миллисекунд (см. рис. 3.4.). Пока процесс находится рядом с процессором, он получает процессор в свое распоряжение и может исполняться.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>+-----------------------------------+</span></span>
<span class="line"><span>|         Карусель процессов        |</span></span>
<span class="line"><span>|  +---+  +---+  +---+  +---+       |</span></span>
<span class="line"><span>|  | P0|  | P1|  | P2|  | P3| ...   |</span></span>
<span class="line"><span>|  +---+  +---+  +---+  +---+       |</span></span>
<span class="line"><span>|    |      |      |      |         |</span></span>
<span class="line"><span>|    v      v      v      v         |</span></span>
<span class="line"><span>| +------------------------------+  |</span></span>
<span class="line"><span>| |           Процессор          |  |</span></span>
<span class="line"><span>| +------------------------------+  |</span></span>
<span class="line"><span>+-----------------------------------+</span></span></code></pre></div><p><em>Рис. 3.4. Процессы на карусели</em></p><p>При выполнении процесса возможны два варианта:</p><ul><li>Время непрерывного использования процессора, необходимое процессу (остаток текущего CPU burst), меньше или равно продолжительности кванта времени. Тогда процесс по своей воле освобождает процессор до истечения кванта времени, на исполнение поступает новый процесс из начала очереди, и таймер начинает отсчет кванта заново.</li><li>Продолжительность остатка текущего CPU burst процесса больше, чем квант времени. Тогда по истечении этого кванта процесс прерывается таймером и помещается в конец очереди процессов, готовых к исполнению, а процессор выделяется для использования процессу, находящемуся в ее начале.</li></ul><p>Рассмотрим предыдущий пример с порядком процессов p0, p1, p2 и величиной кванта времени равной 4. Выполнение этих процессов иллюстрируется таблицей ниже. Обозначение «И» используется в ней для процесса, находящегося в состоянии исполнение, обозначение «Г» — для процессов в состоянии готовность, пустые ячейки соответствуют завершившимся процессам. Состояния процессов показаны на протяжении соответствующей единицы времени, т. е. колонка с номером 1 соответствует промежутку времени от 0 до 1.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Время:   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18</span></span>
<span class="line"><span>p0:      И   И   И   И   Г   Г   Г   Г   Г   И   И   И   И   И   И   И   И   И</span></span>
<span class="line"><span>p1:      Г   Г   Г   Г   И   И   И   И</span></span>
<span class="line"><span>p2:      Г   Г   Г   Г   Г   Г   Г   Г   И</span></span></code></pre></div><p><em>Таблица 3.2.</em></p><p>Первым для исполнения выбирается процесс p0. Продолжительность его CPU burst больше, чем величина кванта времени, и поэтому процесс исполняется до истечения кванта, т. е. в течение 4 единиц времени. После этого он помещается в конец очереди готовых к исполнению процессов, которая принимает вид p1, p2, p0. Следующим начинает выполняться процесс p1. Время его исполнения совпадает с величиной выделенного кванта, поэтому процесс работает до своего завершения. Теперь очередь процессов в состоянии готовность состоит из двух процессов, p2 и p0. Процессор выделяется процессу p2. Он завершается до истечения отпущенного ему процессорного времени, и очередные кванты отмеряются процессу p0 — единственному не закончившему к этому моменту свою работу. Время ожидания для процесса p0 (количество символов «Г» в соответствующей строке) составляет 5 единиц времени, для процесса p1 – 4 единицы времени, для процесса p2 – 8 единиц времени. Таким образом, среднее время ожидания для этого алгоритма получается равным (5 + 4 + 8)/3 = 5,6(6) единицы времени. Полное время выполнения для процесса p0 (количество непустых столбцов в соответствующей строке) составляет 18 единиц времени, для процесса p1 – 8 единиц, для процесса p2 – 9 единиц. Среднее полное время выполнения оказывается равным (18 + 8 + 9)/3 = 11,6(6) единицы времени.</p><p>Легко увидеть, что среднее время ожидания и среднее полное время выполнения для обратного порядка процессов не отличаются от соответствующих времен для алгоритма FCFS и составляют 2 и 6 единиц времени соответственно.</p><p>На производительность алгоритма RR сильно влияет величина кванта времени. Рассмотрим тот же самый пример с порядком процессов p0, p1, p2 для величины кванта времени, равной 1 (см. табл. 3.3.). Время ожидания для процесса p0 составит 5 единиц времени, для процесса p1 – тоже 5 единиц, для процесса p2 – 2 единицы. В этом случае среднее время ожидания получается равным (5 + 5 + 2)/3 = 4 единицам времени. Среднее полное время исполнения составит (18 + 9 + 3)/3 = 10 единиц времени.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Таблица 3.3.</span></span>
<span class="line"><span>Время      1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18</span></span>
<span class="line"><span>p0         И Г Г И Г И Г И Г И И И И И И И И И</span></span>
<span class="line"><span>p1         Г И Г Г И Г И Г И</span></span>
<span class="line"><span>p2         Г Г И</span></span></code></pre></div><p>При очень больших величинах кванта времени, когда каждый процесс успевает завершить свой CPU burst до возникновения прерывания по времени, алгоритм RR вырождается в алгоритм FCFS. При очень малых величинах создается иллюзия того, что каждый из n процессов работает на собственном виртуальном процессоре с производительностью ~1/n от производительности реального процессора. Правда, это справедливо лишь при теоретическом анализе при условии пренебрежения временами переключения контекста процессов. В реальных условиях при слишком малой величине кванта времени и, соответственно, слишком частом переключении контекста накладные расходы на переключение резко снижают производительность системы.</p><p><strong>Кооперация процессов и основные аспекты ее логической организации</strong></p><p>Одной из функций операционной системы является обеспечение санкционированного взаимодействия процессов. Лекция посвящена основам логической организации такого взаимодействия. Рассматривается расширение понятия процесс -- нить исполнения (thread).</p><p>Взаимодействие процессов в вычислительной системе напоминает жизнь в коммунальной квартире. Постоянное ожидание в очереди к местам общего пользования (процессору) и ежедневная борьба за ресурсы (кто опять занял все конфорки на плите?). Для нормального функционирования процессов операционная система старается максимально обособить их друг от друга. Каждый процесс имеет собственное адресное пространство (каждая семья должна жить в отдельной комнате), нарушение которого, как правило, приводит к аварийной остановке процесса (вызов милиции). Каждому процессу по возможности предоставляются свои дополнительные ресурсы (каждая семья предпочитает иметь собственный холодильник). Тем не менее для решения некоторых задач (приготовление праздничного стола на всю квартиру) процессы могут объединять свои усилия. В настоящей лекции описываются причины взаимодействия процессов, способы их взаимодействия и возникающие при этом проблемы (попробуйте отремонтировать общую квартиру так, чтобы жильцы не перессорились друг с другом).</p><p><strong>Взаимодействующие процессы</strong></p><p>Для достижения поставленной цели различные процессы (возможно, даже принадлежащие разным пользователям) могут исполняться псевдопараллельно на одной вычислительной системе или параллельно на разных вычислительных системах, взаимодействуя между собой.</p><p>Для чего процессам нужно заниматься совместной деятельностью? Какие существуют причины для их кооперации?</p><ul><li>Повышение скорости работы. Пока один процесс ожидает наступления некоторого события (например, окончания операции ввода-вывода), другие могут заниматься полезной работой, направленной на решение общей задачи. В многопроцессорных вычислительных системах программа разбивается на отдельные кусочки, каждый из которых будет исполняться на своем процессоре.</li><li>Совместное использование данных. Различные процессы могут, к примеру, работать с одной и той же динамической базой данных или с разделяемым файлом, совместно изменяя их содержимое.</li><li>Модульная конструкция какой-либо системы. Типичным примером может служить микроядерный способ построения операционной системы, когда различные ее части представляют собой отдельные процессы, взаимодействующие путем передачи сообщений через микроядро.</li><li>Наконец, это может быть необходимо просто для удобства работы пользователя, желающего, например, редактировать и отлаживать программу одновременно. В этой ситуации процессы редактора и отладчика должны уметь взаимодействовать друг с другом.</li></ul><p>Процессы не могут взаимодействовать, не общаясь, то есть не обмениваясь информацией. &quot;Общение&quot; процессов обычно приводит к изменению их поведения в зависимости от полученной информации. Если деятельность процессов остается неизменной при любой принятой ими информации, то это означает, что они на самом деле в &quot;общении&quot; не нуждаются. Процессы, которые влияют на поведение друг друга путем</p><p>Основы операционных систем 41</p><p>обмена информацией, принято называть кооперативными или взаимодействующими процессами, в отличие от независимых процессов, не оказывающих друг на друга никакого воздействия.</p><p>Различные процессы в вычислительной системе изначально представляют собой обособленные сущности. Работа одного процесса не должна приводить к нарушению работы другого процесса. Для этого, в частности, разделены их адресные пространства и системные ресурсы, и для обеспечения корректного взаимодействия процессов требуются специальные средства и действия операционной системы. Нельзя просто поместить значение, вычисленное в одном процессе, в область памяти, соответствующую переменной в другом процессе, не предприняв каких-либо дополнительных усилий. Давайте рассмотрим основные аспекты организации совместной работы процессов.</p><p><strong>Категории средств обмена информацией</strong></p><p>Процессы могут взаимодействовать друг с другом, только обмениваясь информацией. По объему передаваемой информации и степени возможного воздействия на поведение другого процесса все средства такого обмена можно разделить на три категории.</p><ul><li><strong>Сигнальные.</strong> Передается минимальное количество информации -- один бит, &quot;да&quot; или &quot;нет&quot;. Используются, как правило, для извещения процесса о наступлении какого-либо события. Степень воздействия на поведение процесса, получившего информацию, минимальна. Все зависит от того, знает ли он, что означает полученный сигнал, надо ли на него реагировать и каким образом. Неправильная реакция на сигнал или его игнорирование могут привести к трагическим последствиям. Вспомним профессора Плейшнера из кинофильма &quot;Семнадцать мгновений весны&quot;. Сигнал тревоги -- цветочный горшок на подоконнике -- был ему передан, но профессор проигнорировал его. И к чему это привело?</li><li><strong>Канальные.</strong> &quot;Общение&quot; процессов происходит через линии связи, предоставленные операционной системой, и напоминает общение людей по телефону, с помощью записок, писем или объявлений. Объем передаваемой информации в единицу времени ограничен пропускной способностью линий связи. С увеличением количества информации возрастает и возможность влияния на поведение другого процесса.</li><li><strong>Разделяемая память.</strong> Два или более процессов могут совместно использовать некоторую область адресного пространства. Созданием разделяемой памяти занимается операционная система (если, конечно, ее об этом попросят). &quot;Общение&quot; процессов напоминает совместное проживание студентов в одной комнате общежития. Возможность обмена информацией максимальна, как, впрочем, и влияние на поведение другого процесса, но требует повышенной осторожности (если вы переложили на другое место вещи вашего соседа по комнате, а часть из них еще и выбросили). Использование разделяемой памяти для передачи/получения информации осуществляется с помощью средств обычных языков программирования, в то время как сигнальным и канальным средствам коммуникации для этого необходимы специальные системные вызовы. Разделяемая память представляет собой наиболее быстрый способ взаимодействия процессов в одной вычислительной системе.</li></ul>`,137)]))}const g=a(l,[["render",t]]);export{o as __pageData,g as default};
