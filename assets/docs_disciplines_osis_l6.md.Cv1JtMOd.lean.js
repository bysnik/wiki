import{_ as t,c as s,o as l,j as a}from"./chunks/framework.D4Vqf8I7.js";const f=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"docs/disciplines/osis/l6.md","filePath":"docs/disciplines/osis/l6.md","lastUpdated":1759480134000}'),n={name:"docs/disciplines/osis/l6.md"};function i(r,e,p,u,o,c){return l(),s("div",null,e[0]||(e[0]=[a("p",null,"Виртуальная память. Архитектурные средства поддержки виртуальной памяти. Аппаратнонезависимый уровень управления виртуальной памятью",-1),a("p",null,'Основы операционных систем 91 Простейший алгоритм. Каждой странице присваивается временная метка. Реализуется это просто созда- нием очереди страниц, в конец которой страницы попадают, когда загружаются в физическую память, а из начала берутся, когда требуется освободить память. Для замещения выбирается старейшая страница. К сожалению, эта стратегия с достаточной вероятностью будет приводить к замещению активно исполь- зуемых страниц, например страниц кода текстового процессора при редактировании файла. Заметим, что при замещении активных страниц все работает корректно, но page fault происходит немедленно. Аномалия Билэди (Belady) На первый взгляд кажется очевидным, что чем больше в памяти страничных кадров, тем реже будут иметь место page faults. Удивительно, но это не всегда так. Как установил Билэди с коллегами, опреде- ленные последовательности обращений к страницам в действительности приводят к увеличению числа страничных нарушений при увеличении кадров, выделенных процессу. Это явление носит название "аномалии Билэди" или "аномалии FIFO". Система с тремя кадрами (9 faults) оказывается более производительной, чем с четырьмя кадрами (10 faults), для строки обращений к памяти 012301401234 при выборе стратегии FIFO. Рис. 10.1. Аномалия Билэди: (a) - FIFO с тремя страничными кадрами; (b) - FIFO с четырьмя страничными кадрами Аномалию Билэди следует считать скорее курьезом, чем фактором, требующим серьезного отношения, который иллюстрирует сложность ОС, где интуитивный подход не всегда приемлем. Оптимальный алгоритм (OPT) Одним из последствий открытия аномалии Билэди стал поиск оптимального алгоритма, который при за- данной строке обращений имел бы минимальную частоту page faults среди всех других алгоритмов. Та- кой алгоритм был найден. Он прост: замещай страницу, которая не будет использоваться в течение само- го длительного периода времени. Каждая страница должна быть помечена числом инструкций, которые будут выполнены, прежде чем на эту страницу будет сделана первая ссылка. Выталкиваться должна страница, для которой это число наи- большее. Этот алгоритм легко описать, но реализовать невозможно. ОС не знает, к какой странице будет следую- щее обращение. (Ранее такие проблемы возникали при планировании процессов - алгоритм SJF). Основы операционных систем 92 Зато мы можем сделать вывод, что для того, чтобы алгоритм замещения был максимально близок к иде- альному алгоритму, система должна как можно точнее предсказывать обращения процессов к памяти. Данный алгоритм применяется для оценки качества реализуемых алгоритмов. Выталкивание дольше всего не использовавшейся страницы. Алгоритм LRU Одним из приближений к алгоритму OPT является алгоритм, исходящий из эвристического правила, что недавнее прошлое - хороший ориентир для прогнозирования ближайшего будущего. Ключевое отличие между FIFO и оптимальным алгоритмом заключается в том, что один смотрит назад, а другой вперед. Если использовать прошлое для аппроксимации будущего, имеет смысл замещать стра- ницу, которая не использовалась в течение самого долгого времени. Такой подход называется least recently used алгоритм (LRU). Работа алгоритма проиллюстрирована на рис. рис. 10.2. Сравнивая рис. 10.1 b и 10.2, можно увидеть, что использование LRU алгоритма позволяет сократить количество стра- ничных нарушений. Рис. 10.2. Пример работы алгоритма LRU LRU - хороший, но труднореализуемый алгоритм. Необходимо иметь связанный список всех страниц в памяти, в начале которого будут хранится недавно использованные страницы. Причем этот список дол- жен обновляться при каждом обращении к памяти. Много времени нужно и на поиск страниц в таком списке. В [Таненбаум, 2002] рассмотрен вариант реализации алгоритма LRU со специальным 64-битным указа- телем, который автоматически увеличивается на единицу после выполнения каждой инструкции, а в таб- лице страниц имеется соответствующее поле, в которое заносится значение указателя при каждой ссылке на страницу. При возникновении page fault выгружается страница с наименьшим значением этого поля. Как оптимальный алгоритм, так и LRU не страдают от аномалии Билэди. Существует класс алгоритмов, для которых при одной и той же строке обращений множество страниц в памяти для n кадров всегда яв- ляется подмножеством страниц для n+1 кадра. Эти алгоритмы не проявляют аномалии Билэди и называ- ются стековыми (stack) алгоритмами. Выталкивание редко используемой страницы. Алгоритм NFU Поскольку большинство современных процессоров не предоставляют соответствующей аппаратной под- держки для реализации алгоритма LRU, хотелось бы иметь алгоритм, достаточно близкий к LRU, но не требующий специальной поддержки. Программная реализация алгоритма, близкого к LRU, - алгоритм NFU(Not Frequently Used). Для него требуются программные счетчики, по одному на каждую страницу, которые сначала равны ну- лю. При каждом прерывании по времени (а не после каждой инструкции) операционная система скани- рует все страницы в памяти и у каждой страницы с установленным флагом обращения увеличивает на единицу значение счетчика, а флаг обращения сбрасывает. Таким образом, кандидатом на освобождение оказывается страница с наименьшим значением счетчика, как страница, к которой реже всего обращались. Главный недостаток алгоритма NFU состоит в том, что Основы операционных систем 93 он ничего не забывает. Например, страница, к которой очень часто обращались в течение некоторого времени, а потом обращаться перестали, все равно не будет удалена из памяти, потому что ее счетчик со- держит большую величину. Например, в многопроходных компиляторах страницы, которые активно ис- пользовались во время первого прохода, могут надолго сохранить большие значения счетчика, мешая за- грузке полезных в дальнейшем страниц. К счастью, возможна небольшая модификация алгоритма, которая позволяет ему "забывать". Достаточно, чтобы при каждом прерывании по времени содержимое счетчика сдвигалось вправо на 1 бит, а уже затем производилось бы его увеличение для страниц с установленным флагом обращения. Другим, уже более устойчивым недостатком алгоритма является длительность процесса сканирования таблиц страниц. Другие алгоритмы Для полноты картины можно упомянуть еще несколько алгоритмов. Например, алгоритм Second-Chance - модификация алгоритма FIFO, которая позволяет избежать потери часто используемых страниц с помощью анализа флага обращений (бита ссылки) для самой старой стра- ницы. Если флаг установлен, то страница, в отличие от алгоритма FIFO, не выталкивается, а ее флаг сбрасывается, и страница переносится в конец очереди. Если первоначально флаги обращений были ус- тановлены для всех страниц (на все страницы ссылались), алгоритм Second-Chance превращается в алго- ритм FIFO. Данный алгоритм использовался в Multics и BSD Unix. В компьютере Macintosh использован алгоритм NRU (Not Recently-Used), где страница-"жертва" выбира- ется на основе анализа битов модификации и ссылки. Интересные стратегии, основанные на буферизации страниц, реализованы в VAX/VMS и Mach. Имеется также и много других алгоритмов замещения. Объем этого курса не позволяет рассмотреть их подробно. Подробное описание различных алгоритмов замещения можно найти в монографиях [Дейтел, 1987], [Цикритис, 1977], [Таненбаум, 2002] и др. Управление количеством страниц, выделенным процессу. Модель рабочего множества В стратегиях замещения, рассмотренных в предыдущем разделе, прослеживается предположение о том, что количество кадров, принадлежащих процессу, нельзя увеличить. Это приводит к необходимости вы- талкивания страницы. Рассмотрим более общий подход, базирующийся на концепции рабочего множест- ва, сформулированной Деннингом [Denning, 1996]. Итак, что делать, если в распоряжении процесса имеется недостаточное число кадров? Нужно ли его приостановить с освобождением всех кадров? Что следует понимать под достаточным количеством кад- ров? Трешинг (Thrashing) Хотя теоретически возможно уменьшить число кадров процесса до минимума, существует какое-то чис- ло активно используемых страниц, без которого процесс часто генерирует page faults. Высокая частота страничных нарушений называется трешинг (thrashing, иногда употребляется русский термин "пробук- совка", см. рис. 10.3). Процесс находится в состоянии трешинга, если при его работе больше времени уходит на подкачку страниц, нежели на выполнение команд. Такого рода критическая ситуация возника- ет вне зависимости от конкретных алгоритмов замещения. Основы операционных систем 94 Рис. 10.3. Частота page faults в зависимости от количества кадров, выделенных процессу Часто результатом трешинга является снижение производительности вычислительной системы. Один из нежелательных сценариев развития событий может выглядеть следующим образом. При глобальном ал- горитме замещения процесс, которому не хватает кадров, начинает отбирать кадры у других процессов, которые в свою очередь начинают заниматься тем же. В результате все процессы попадают в очередь за- просов к устройству вторичной памяти (находятся в состоянии ожидания), а очередь процессов в состоя- нии готовности пустеет. Загрузка процессора снижается. Операционная система реагирует на это увели- чением степени мультипрограммирования, что приводит к еще большему трешингу и дальнейшему сни- жению загрузки процессора. Таким образом, пропускная способность системы падает из-за трешинга. Эффект трешинга, возникающий при использовании глобальных алгоритмов, может быть ограничен за счет применения локальных алгоритмов замещения. При локальных алгоритмах замещения если даже один из процессов попал в трешинг, это не сказывается на других процессах. Однако он много времени проводит в очереди к устройству выгрузки, затрудняя подкачку страниц остальных процессов. Критическая ситуация типа трешинга возникает вне зависимости от конкретных алгоритмов замещения. Единственным алгоритмом, теоретически гарантирующим отсутствие трешинга, является рассмотренный выше не реализуемый на практике оптимальный алгоритм. Итак, трешинг - это высокая частота страничных нарушений. Hеобходимо ее контролировать. Когда она высока, процесс нуждается в кадрах. Можно, устанавливая желаемую частоту page faults, регулировать размер процесса, добавляя или отнимая у него кадры. Может оказаться целесообразным выгрузить про- цесс целиком. Освободившиеся кадры выделяются другим процессам с высокой частотой page faults. Для предотвращения трешинга требуется выделять процессу столько кадров, сколько ему нужно. Hо как узнать, сколько ему нужно? Необходимо попытаться выяснить, как много кадров процесс реально ис- пользует. Для решения этой задачи Деннинг использовал модель рабочего множества, которая основана на применении принципа локальности. Модель рабочего множества Рассмотрим поведение реальных процессов. Процессы начинают работать, не имея в памяти необходимых страниц. В результате при выполнении первой же машинной инструкции возникает page fault, требующий подкачки порции кода. Следующий page fault происходит при локализации глобальных переменных и еще один - при выделении памяти для стека. После того как процесс собрал большую часть необходимых ему страниц, page faults возникают редко. Таким образом, существует набор страниц (P1, P2 , ... Pn ), активно использующихся вместе, который по- зволяет процессу в момент времени t в течение некоторого периода T производительно работать, избегая большого количества page faults. Этот набор страниц называется рабочим множеством W(t,T) (working set) процесса. Число страниц в рабочем множестве определяется параметром Т, является неубывающей функцией T и относительно невелико. Иногда T называют размером окна рабочего множества, через ко- торое ведется наблюдение за процессом (см. рис. 10.4). Основы операционных систем 95 Рис. 10.4. Пример рабочего множества процесса Легко написать тестовую программу, которая систематически работает с большим диапазоном адресов, но, к счастью, большинство реальных процессов не ведут себя подобным образом, а проявляют свойство локальности. В течение любой фазы вычислений процесс работает с небольшим количеством страниц. Когда процесс выполняется, он двигается от одного рабочего множества к другому. Программа обычно состоит из нескольких рабочих множеств, которые могут перекрываться. Hапример, когда вызвана про- цедура, она определяет новое рабочее множество, состоящее из страниц, содержащих инструкции проце- дуры, ее локальные и глобальные переменные. После ее завершения процесс покидает это рабочее мно- жество, но может вернуться к нему при новом вызове процедуры. Таким образом, рабочее множество оп- ределяется кодом и данными программы. Если процессу выделять меньше кадров, чем ему требуется для поддержки рабочего множества, он будет находиться в состоянии трешинга. Принцип локальности ссылок препятствует частым изменениям рабочих наборов процессов. Формально это можно выразить следующим образом. Если в период времени (t-T, t) программа обращалась к стра- ницам W(t,T), то при надлежащем выборе T с большой вероятностью эта программа будет обращаться к тем же страницам в период времени (t, t+T). Другими словами, принцип локальности утверждает, что ес- ли не слишком далеко заглядывать в будущее, то можно достаточно точно его прогнозировать исходя из прошлого. Понятно, что с течением времени рабочий набор процесса может изменяться (как по составу страниц, так и по их числу). Наиболее важное свойство рабочего множества - его размер. ОС должна выделить каждому процессу достаточное число кадров, чтобы поместилось его рабочее множество. Если кадры еще остались, то мо- жет быть инициирован другой процесс. Если рабочие множества процессов не помещаются в память и начинается трешинг, то один из процессов можно выгрузить на диск. Решение о размещении процессов в памяти должно, следовательно, базироваться на размере его рабочего множества. Для впервые инициируемых процессов это решение может быть принято эвристически. Во время работы процесса система должна уметь определять: расширяет процесс свое рабочее множество или перемещается на новое рабочее множество. Если в состав атрибутов страницы включить время по- следнего использования t i (для страницы с номером i), то принадлежность i-й страницы к рабочему набо- ру, определяемому параметром T в момент времени t будет выражаться неравенством: t-T < t i < t. Алго- ритм выталкивания страниц WSClock, использующий информацию о рабочем наборе процесса, описан в [Таненбаум, 2002]. Другой способ реализации данного подхода может быть основан на отслеживании количества странич- ных нарушений, вызываемых процессом. Если процесс часто генерирует page faults и память не слишком заполнена, то система может увеличить число выделенных ему кадров. Если же процесс не вызывает ис- ключительных ситуаций в течение некоторого времени и уровень генерации ниже какого-то порога, то число кадров процесса может быть урезано. Этот способ регулирует лишь размер множества страниц, принадлежащих процессу, и должен быть дополнен какой-либо стратегией замещения страниц. Несмотря на то что система при этом может пробуксовывать в моменты перехода от одного рабочего множества к другому, предлагаемое решение в состоянии обеспечить наилучшую производительность для каждого процесса, не требуя никакой дополнительной настройки системы. Страничные демоны Подсистема виртуальной памяти работает производительно при наличии резерва свободных страничных кадров. Алгоритмы, обеспечивающие поддержку системы в состоянии отсутствия трешинга, реализова- ны в составе фоновых процессов (их часто называют демонами или сервисами), которые периодически "просыпаются" и инспектируют состояние памяти. Если свободных кадров оказывается мало, они могут Основы операционных систем 96 сменить стратегию замещения. Их задача - поддерживать систему в состоянии наилучшей производи- тельности. Примером такого рода процесса может быть фоновый процесс - сборщик страниц, реализующий облег- ченный вариант алгоритма откачки, основанный на использовании рабочего набора и применяемый во многих клонах ОС Unix (см., например,[Bach, 1986]). Данный демон производит откачку страниц, не входящих в рабочие наборы процессов. Он начинает активно работать, когда количество страниц в спи- ске свободных страниц достигает установленного нижнего порога, и пытается выталкивать страницы в соответствии с собственной стратегией. Но если возникает требование страницы в условиях, когда список свободных страниц пуст, то начинает работать механизм свопинга, поскольку простое отнятие страницы у любого процесса (включая тот, ко- торый затребовал бы страницу) потенциально вело бы к ситуации thrashing, и разрушало бы рабочий на- бор некоторого процесса. Любой процесс, затребовавший страницу не из своего текущего рабочего набо- ра, становится в очередь на выгрузку в расчете на то, что после завершения выгрузки хотя бы одного из процессов свободной памяти уже может быть достаточно. В ОС Windows 2000 аналогичную роль играет менеджер балансного набора (Working set manager), кото- рый вызывается раз в секунду или тогда, когда размер свободной памяти опускается ниже определенного предела, и отвечает за суммарную политику управления памятью и поддержку рабочих множеств. Программная поддержка сегментной модели памяти процесса Реализация функций операционной системы, связанных с поддержкой памяти, - ведение таблиц страниц, трансляция адреса, обработка страничных ошибок, управление ассоциативной памятью и др. - тесно свя- зана со структурами данных, обеспечивающими удобное представление адресного пространства процес- са. Формат этих структур сильно зависит от аппаратуры и особенностей конкретной ОС. Чаще всего виртуальная память процесса ОС разбивается на сегменты пяти типов: кода программы, дан- ных, стека, разделяемый и сегмент файлов, отображаемых в память (см. рис. 10.5). Сегмент программного кода содержит только команды. Сегмент программного кода не модифицирует- ся в ходе выполнения процесса, обычно страницы данного сегмента имеют атрибут read-only. Следстви- ем этого является возможность использования одного экземпляра кода для разных процессов. Сегмент данных, содержащий переменные программы и сегмент стека, содержащий автоматические пе- ременные, могут динамически менять свой размер (обычно данные в сторону увеличения адресов, а стек',-1),a("ul",null,[a("li",null,'в сторону уменьшения) и содержимое, должны быть доступны по чтению и записи и являются приват- ными сегментами процесса. Рис. 10.5. Образ процесса в памяти Основы операционных систем 97 С целью обобществления памяти между несколькими процессами создаются разделяемые сегменты, допускающие доступ по чтению и записи. Вариантом разделяемого сегмента может быть сегмент файла, отображаемого в память. Специфика таких сегментов состоит в том, что из них откачка осуществляется не в системную область выгрузки, а непосредственно в отображаемый файл. Реализация разделяемых сегментов основана на том, что логические страницы различных процессов связываются с одними и теми же страничными кадрами. Сегменты представляют собой непрерывные области (в Linux они так и называются - области) в вирту- альном адресном пространстве процесса, выровненные по границам страниц. Каждая область состоит из набора страниц с одним и тем же режимом защиты. Между областями в виртуальном пространстве могут быть свободные участки. Естественно, что подобные объекты описаны соответствующими структурами (см., например, структуры mm_struct и vm_area_struct в Linux). Часть работы по организации сегментов может происходить с участием программиста. Особенно это за- метно при низкоуровневом программировании. В частности, отдельные области памяти могут быть по- именованы и использоваться для обмена данными между процессами. Два процесса могут общаться че- рез разделяемую область памяти при условии, что им известно ее имя (пароль). Обычно это делается при помощи специальных вызовов (например, map и unmap), входящих в состав интерфейса виртуальной па- мяти. Загрузка исполняемого файла (системный вызов exec) осуществляется обычно через отображение (mapping) его частей (кода, данных) в соответствующие сегменты адресного пространства процесса. На- пример, сегмент кода является сегментом отображаемого в память файла, содержащего исполняемую программу. При попытке выполнить первую же инструкцию система обнаруживает, что нужной части кода в памяти нет, генерирует page fault и подкачивает эту часть кода с диска. Далее процедура повторя- ется до тех пор, пока вся программа не окажется в оперативной памяти. Как уже говорилось, размер сегмента данных динамически меняется. Рассмотрим, как организована под- держка сегментов данных в Unix. Пользователь, запрашивая (библиотечные вызовы malloc, new) или ос- вобождая (free, delete) память для динамических данных, фактически изменяет границу выделенной про- цессу памяти через системный вызов brk (от слова break), который модифицирует значение переменной brk из структуры данных процесса. В результате происходит выделение физической памяти, граница brk смещается в сторону увеличения виртуальных адресов, а соответствующие строки таблиц страниц полу- чают осмысленные значения. При помощи того же вызова brk пользователь может уменьшить размер сегмента данных. На практике освобожденная пользователем виртуальная память (библиотечные вызовы free, delete) системе не возвращается. На это есть две причины. Во-первых, для уменьшения размеров сегмента данных необходимо организовать его уплотнение или "сборку мусора". А во-вторых, незанятые внутри сегмента данных области естественным образом будут вытолкнуты из оперативной памяти вслед- ствие того, что к ним не будет обращений. Ведение списков занятых и свободных областей памяти в сег- менте данных пользователя осуществляется на уровне системных библиотек. Более подробно информация об адресных пространствах процессов в Unix изложена в [Кузнецов], [Bach, 1986]. Отдельные аспекты функционирования менеджера памяти Корректная работа менеджера памяти помимо принципиальных вопросов, связанных с выбором абст- рактной модели виртуальной памяти и ее аппаратной поддержкой, обеспечивается также множеством нюансов и мелких деталей. В качестве примера такого рода компонента рассмотрим более подробно ло- кализацию страниц в памяти, которая применяется в тех случаях, когда поддержка страничной систе- мы приводит к необходимости разрешить определенным страницам, хранящим буферы ввода-вывода, другие важные данные и код, быть блокированными в памяти. Рассмотрим случай, когда система виртуальной памяти может вступить в конфликт с подсистемой ввода- вывода. Например, процесс может запросить ввод в буфер и ожидать его завершения. Управление пере- дастся другому процессу, который может вызвать page fault и, с отличной от нуля вероятностью, спрово- цировать выгрузку той страницы, куда должен быть осуществлен ввод первым процессом. Подобные си- Основы операционных систем 98 туации нуждаются в дополнительном контроле, особенно если ввод-вывод реализован с использованием механизма прямого доступа к памяти (DMA). Одно из решений данной проблемы - вводить данные в не вытесняемый буфер в пространстве ядра, а затем копировать их в пользовательское пространство. Второе решение - локализовать страницы в памяти, используя специальный бит локализации, входящий в состав атрибутов страницы. Локализованная страница замещению не подлежит. Бит локализации сбра- сывается после завершения операции ввода-вывода. Другое использование бита локализации может иметь место и при нормальном замещении страниц. Рас- смотрим следующую цепь событий. Низкоприоритетный процесс после длительного ожидания получил в свое распоряжение процессор и подкачал с диска нужную ему страницу. Если он сразу после этого будет вытеснен высокоприоритетным процессом, последний может легко заместить вновь подкачанную стра- ницу низкоприоритетного, так как на нее не было ссылок. Имеет смысл вновь загруженные страницы помечать битом локализации до первой ссылки, иначе низкоприоритетный процесс так и не начнет рабо- тать. Использование бита локализации может быть опасным, если забыть его отключить. Если такая ситуация имеет место, страница становится неиспользуемой. SunOS разрешает использование данного бита в каче- стве подсказки, которую можно игнорировать, когда пул свободных кадров становится слишком малень- ким. Другим важным применением локализации является ее использование в системах мягкого реального времени. Рассмотрим процесс или нить реального времени. Вообще говоря, виртуальная память - анти- теза вычислений реального времени, так как дает непредсказуемые задержки при подкачке страниц. По- этому системы реального времени почти не используют виртуальную память. ОС Solaris поддерживает как реальное время, так и разделение времени. Для решения проблемы page faults, Solaris разрешает про- цессам сообщать системе, какие страницы важны для процесса, и локализовать их в памяти. В результате возможно выполнение процесса, реализующего задачу реального времени, содержащего локализованные страницы, где временные задержки страничной системы будут минимизированы. Помимо системы локализации страниц, есть и другие интересные проблемы, возникающие в процессе управления памятью. Так, например, бывает непросто осуществить повторное выполнение инструкции, вызвавшей page fault. Представляют интерес и алгоритмы отложенного выделения памяти (копирование при записи и др.). Ограниченный объем данного курса не позволяет рассмотреть их более подробно. Заключение Описанная система управления памятью является совокупностью программно-технических средств, обеспечивающих производительное функционирование современных компьютеров. Успех реализации той части ОС, которая относится к управлению виртуальной памятью, определяется близостью архитек- туры аппаратных средств, поддерживающих виртуальную память, к абстрактной модели виртуальной памяти ОС. Справедливости ради заметим, что в подавляющем большинстве современных компьютеров аппаратура выполняет функции, существенно превышающие потребности модели ОС, так что создание аппаратно-зависимой части подсистемы управления виртуальной памятью ОС в большинстве случаев не является чрезмерно сложной задачей.')],-1)]))}const g=t(n,[["render",i]]);export{f as __pageData,g as default};
